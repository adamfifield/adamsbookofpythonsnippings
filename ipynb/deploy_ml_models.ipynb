{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492e7511",
   "metadata": {},
   "source": [
    "\n",
    "# üöÄ Deploying Machine Learning Models with FastAPI & Streamlit\n",
    "\n",
    "This notebook provides **code templates and checklists** for **deploying ML models as APIs using FastAPI and creating simple web apps with Streamlit**.\n",
    "\n",
    "### üîπ What‚Äôs Covered:\n",
    "- Saving and loading trained ML models\n",
    "- Deploying models using FastAPI\n",
    "- Querying APIs with `requests`\n",
    "- Building a web UI with Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure required libraries are installed (Uncomment if necessary)\n",
    "# !pip install fastapi uvicorn joblib requests streamlit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bb338",
   "metadata": {},
   "source": [
    "\n",
    "## üíæ Saving & Loading Trained Models\n",
    "\n",
    "‚úÖ Use **joblib** or **pickle** to serialize models.  \n",
    "‚úÖ Ensure models can be **loaded without retraining**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91386991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a sample model\n",
    "model = LogisticRegression()\n",
    "X_sample, y_sample = [[1, 2], [3, 4]], [0, 1]\n",
    "model.fit(X_sample, y_sample)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"ml_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load(\"ml_model.pkl\")\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b55d75",
   "metadata": {},
   "source": [
    "\n",
    "## üåç Deploying a Model with FastAPI\n",
    "\n",
    "‚úÖ Create a **FastAPI endpoint** to serve predictions.  \n",
    "‚úÖ Use `uvicorn` to run the API locally.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save this as api.py and run with `uvicorn api:app --reload`\n",
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load(\"ml_model.pkl\")\n",
    "\n",
    "@app.get(\"/predict/\")\n",
    "def predict(feature1: float, feature2: float):\n",
    "    prediction = model.predict(np.array([[feature1, feature2]]))\n",
    "    return {\"prediction\": int(prediction[0])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a40a0b",
   "metadata": {},
   "source": [
    "\n",
    "## üîó Querying the API with Requests\n",
    "\n",
    "‚úÖ Send a **GET request** to the FastAPI endpoint.  \n",
    "‚úÖ Parse the JSON response.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "# Send a request to the FastAPI server (assuming it's running)\n",
    "url = \"http://127.0.0.1:8000/predict/?feature1=2.5&feature2=3.0\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the prediction\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2bca1",
   "metadata": {},
   "source": [
    "\n",
    "## üñ•Ô∏è Building a Web UI with Streamlit\n",
    "\n",
    "‚úÖ Create a **Streamlit web app** for model inference.  \n",
    "‚úÖ Provide an **interactive user interface** for input.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save this as app.py and run with `streamlit run app.py`\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load(\"ml_model.pkl\")\n",
    "\n",
    "st.title(\"ML Model Deployment\")\n",
    "\n",
    "# User input for prediction\n",
    "feature1 = st.number_input(\"Enter feature 1\", min_value=0.0, max_value=10.0, step=0.1)\n",
    "feature2 = st.number_input(\"Enter feature 2\", min_value=0.0, max_value=10.0, step=0.1)\n",
    "\n",
    "# Make prediction\n",
    "if st.button(\"Predict\"):\n",
    "    prediction = model.predict(np.array([[feature1, feature2]]))\n",
    "    st.write(f\"Prediction: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa5bb8",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Best Practices & Common Pitfalls\n",
    "\n",
    "- **Ensure security**: Never expose models with unrestricted access.  \n",
    "- **Use Docker**: Package APIs for easy deployment (`docker build -t ml_api .`).  \n",
    "- **Monitor performance**: Use logging to track model behavior in production.  \n",
    "- **Test thoroughly**: Validate API responses before deployment.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
